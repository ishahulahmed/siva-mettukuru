Session Overview
-----------------
a) Docker Volumes
b) Docker best practices

volumes:
- unnamed
- named

unnamed means we will create volume in local system and connect using -v host-path:container-path
named volumes means we will create volumes using docker commands and the life cycle of volume will be taken care by docker

-v host-path:container-path

docker run -d -p 80:80 -v /home/ec2-user/nginx-data:/usr/share/nginx/html nginx
host path we need to give completely for unnamed volume creation because docker will not take relative paths.

http://35.171.84.109:80 (it will not work because nginx-data folder have no files 
cd nginx-data
echo "<h1>Hi, I am Learning unnamed volumes</h1>" > index.html
now, it will work because container is referring to the local directory (nginx-data). i.e directory inside the server. you can put even your entire website here.

images size should be less docker best practise. let's see our expense-docker images size.
for i in mysql backend frontend; do cd $i; docker build -t $i:v1.0 . ; cd .. ; done

REPOSITORY   TAG       IMAGE ID       CREATED              SIZE
frontend     v1.0      9b6921366a48   7 seconds ago        189MB
backend      v1.0      65323a9f4f8c   11 seconds ago       1.11GB
mysql        v1.0      c9e0d38cacd8   About a minute ago   572MB

here frontend or more in size we will decrease there size using alpine because it is the most small image. we will not play with mysql since it is stateful application. we will only make changes to stateless applications in such a way that image size should less and it should be fully in working condition. in quest for reducing the size we should not compromise on it's practical application. both, should be balanced.

docker volume create mysql (we creating volume mysql since our docker-compose.yaml have external true for mysql)
docker compose up -d 
so our expense-app is running. but, we need to optimise this by using alpine linux images no we will change our code according in dockerfiles of respective images.

FROM node:20.16.0-alpine3.20 (node.js is 20 but os apline on which node 20 is working)
RUN addgroup -S expense && adduser -S expense -G expense (we need to create group and then add user to it in alpine OS not conform)
cd backend
docker build -t backend:v1.0 (since dockefile is changed we need to build new image)
backend      v1.0      293ddf11f62b   11 seconds ago   152MB
now image size 152MB previous 1.1GB. Now test the application.

1GB app 

single flat 2400 sqft --> only one room --> one family (PG rooms famous it doesn't mean we can accomodate a family in single room of pg)
in the samey way since containerisation is popular we can't put a  big app in a container. if you are getting an image size more than 500MB. First reduce the size of image. change the design of the application. but, people are forcing to using to use big apps in containers. since, management also do not have any experience they are also proceedign this way. but, we should always follow best practises.

6GB apps are also running in containers

Multi stage builds --> Java apps (Mostly Java Applications are Mulit Stage Builds)

JDK --> Java development kit
JRE --> Java runtime environment

JDK > JRE

JDK = JRE + development tools

Developers develop java apps in JDK environment, once you get build package. no need to dev environment


app code --> compile[JDK] --> java bytecode(build file) .jar, .war [JDK]  (Microservies mostly .jar)

run bytecode --> app is up [JRE]

ChatGPT
--------
a) Binary Code is a broader term that refers to any data in binary form. This includes machine code as well as other forms of binary-encoded data.
b) Machine Code is a specific type of binary code that directly interacts with the hardware. It is usually represented in binary or hexadecimal format and 
   consists of instructions that the CPU can execute directly.
c) Bytecode is a intermediate code that is not directly executed by the hardware but requires a virtual machine or interpreter to run. It is usually more 
   portable than machine code

Bytecode
---------
a) Description: Bytecode is a form of intermediate code that is typically generated by compilers for languages that run on a virtual machine (like Java 
                bytecode for the JVM or Python bytecode for the Python interpreter). It is a set of instructions that is more abstract than machine code and 
                is meant to be executed by a virtual machine rather than directly by the hardware.

b) Context: Bytecode is language-specific and designed to be portable across different platforms, requiring a runtime environment (e.g., JVM, Python 
            interpreter) to execute.

Bytecode is not the same for every language. Bytecode is a form of intermediate code used by some programming languages to achieve platform independence and optimize execution. Different languages have their own specific bytecode formats, and each language's bytecode is designed to work with its particular runtime environment. Here's a bit more detail:

1) Java Bytecode:
   a) Description: Java bytecode is a platform-independent intermediate code generated by the Java compiler (javac) from Java source code. It is executed by 
                   the Java Virtual Machine (JVM). Java bytecode is specific to the Java language and the JVM.

2) Python Bytecode:
   a) Description: Python bytecode is generated by the Python interpreter when you run a Python script. It is an intermediate representation of your Python  
                   code and is executed by the Python Virtual Machine (PVM). Python bytecode is specific to the Python language and the Python runtime
                   environment.

3) C# Bytecode (Intermediate Language - IL):
   a) Description: In the .NET ecosystem, C# (and other .NET languages) are compiled into Intermediate Language (IL) or Common Intermediate Language (CIL) 
                   bytecode. This IL bytecode is executed by the .NET Common Language Runtime (CLR).

4) Other Languages:
   a) Description: Many other languages use their own form of bytecode. For example, languages like Kotlin (which also runs on the JVM) generate bytecode 
                   that is compatible with the JVM, while languages like Scala also generate JVM bytecode but include features specific to their own     
                   language constructs.
Key Points to Note:
-------------------
a) Language-Specific: Bytecode is tailored to the specifics of the language and its runtime. Different languages have different bytecode formats and  
                      execution models.
b) Platform Independence: The primary purpose of bytecode is to provide a platform-independent way to execute code. The same source code can be compiled 
                          into the same bytecode and then executed on any platform with the appropriate runtime environment.
c) Optimizations: Different runtime environments might include optimizations or variations in how they handle bytecode execution, such as JIT compilation,  
                  which can affect performance but not the fundamental nature of the bytecode.

JRE
----
The Java Runtime Environment (JRE) does not compile code; it executes bytecode. Here's a clearer breakdown of the roles of different components in the Java ecosystem:

1) Compilation Phase:
   a) Java Compiler (javac): When you write Java source code (.java files), you need to compile it into bytecode. This is done by the Java compiler, javac. 
                             The compiler takes the source code and translates it into bytecode (.class files), which is a platform-independent intermediate 
                             representation of your code.

2) Execution Phase:
   a) Java Runtime Environment (JRE): The JRE is responsible for running the compiled bytecode. It does not compile code; instead, it includes the Java 
                                      Virtual Machine (JVM) that interprets or compiles the bytecode into machine code specific to the host operating 
                                      system.
3) Java Virtual Machine (JVM):
   a) Interpreter: The JVM can execute bytecode directly using an interpreter. This means it reads and executes the bytecode instructions one at a time.
   b) Just-In-Time (JIT) Compiler: For better performance, the JVM often uses a Just-In-Time (JIT) compiler to translate bytecode into native machine code 
                                   at runtime. This native code is then executed directly by the hardware, which can significantly speed up execution 
                                   compared to interpretation alone.

In summary, the JRE does not compile Java code. It runs bytecode produced by the Java compiler and can use the JVM to interpret or compile bytecode into machine code as needed.

Roboshop-shipping
---------------------
Aritficat Extension in node .zip but in java .jar

after npm install in nodejs node_modules directory but for java we will get target directory

a) node_modules directory is a folder typically found in projects that use Node.js for server-side JavaScript development or front-end development workflows 
   involving tools like npm (Node Package Manager) or Yarn.
b) It stores all the external libraries and dependencies that your project uses. These can include frameworks, libraries, modules, utilities, etc., needed 
   to run your application.
c) node_modules is a crucial directory in Node.js projects where all external dependencies are stored, ensuring that your project can access and use the  
   necessary libraries and tools specified in your project configuration (package.json). (like target folder in java)

package.json and pom.xml serve similar high-level purposes of managing dependencies and defining project configurations, but they do so within their own ecosystems and for their respective programming languages (JavaScript/Node.js vs Java). They reflect the different conventions and needs of each ecosystem rather than being directly comparable in terms of functionality beyond dependency management and project configuration.

in target folder there will be jar file if we run that jar file then application will run. that is the file we are looking you can run it directly from dockerfile instructions.
-rw-r--r-- 1 root root 41486756 Jul 28 11:13 shipping-1.0.jar

In the context of Dockerfiles, FROM maven and FROM maven as build are both instructions used to define the base image for building Docker images related to Maven-based projects, but they serve slightly different purposes:

1) FROM maven: This line specifies that the Docker image is based directly on the official Maven image available on Docker Hub. This image typically 
               includes a basic Maven setup with Java, allowing you to run Maven commands directly within your Docker container. For example:
               removing unnecessary files is best practise.
                 
               FROM maven

               # Your Dockerfile instructions here

               Here, you can execute Maven commands such as mvn clean install directly within your Docker container.

2) FROM maven as build: This syntax introduces a multi-stage build in Docker. In a multi-stage build, you can use multiple FROM instructions in a single 
                        Dockerfile. Each FROM instruction starts a new stage of the build. The as build part assigns a name (in this case, build) to the 
                        build stage, which you can refer to later in the Dockerfile.

                        FROM maven as build

                        # Build stage: use this stage to build your Maven project
                        COPY pom.xml .
                        RUN mvn dependency:go-offline

                        COPY src ./src
                        RUN mvn package

                        # Start a new stage to create the runtime image
                        FROM openjdk:11-jre-slim
                        COPY --from=build /target/your-app.jar /app.jar

                        CMD ["java", "-jar", "/app.jar"]

                       In this example:
                       The FROM maven as build line starts the first stage of the build, where Maven is used to compile and package your application.
                       Later in the Dockerfile (FROM openjdk:11-jre-slim), another FROM instruction starts a new stage for creating the runtime image. The  
                       COPY --from=build instruction copies the built artifact from the build stage into the runtime image.
Key Differences:
-------------------

a) Single Stage (FROM maven): This approach creates a single Docker image where Maven is used both for building your application and potentially for running 
                              it.

b) Multi-Stage (FROM maven as build): This approach separates the build process (compiling, testing, packaging) from the final runtime image. It helps  
                                      reduce the size of the final Docker image by discarding unnecessary build dependencies that are only needed during the 
                                      build phase.
Use Cases:
-----------
a) Use FROM maven for simple cases where you just need Maven to build and run your application within a single Docker image.

b) Use FROM maven as build for more complex scenarios where you want to optimize your Docker image size by separating the build environment (Maven) from the 
   runtime environment (e.g., JDK or JRE).

By using Multi Stage Build we can Reduce the size of the image.

if use docker build command it should load all the files the workspace for atleast context purpose whether it will use them or not so use dockerignorefile.
so, please don't keep unnecessary files in the workspace. if you need them in workspace but you don't use for building image use dokcerignore file.

git clone https://github.com/ishahulahmed/shipping.git (clone this shipping project into your server)
mkdir most-secure
cd most-secure
touch credentials
touch credentials-project-a.txt
touch credentials-project-b.txt

let suppose, multiple projects credentials are in this server.

dokcer will not have any original storage. container will use host storage.
we have seen in /var/lib/docker volume directories are getting created. so, all containers will underlying host storage

for example if give
docker run -d -p 8080:80 -v /:/spam nginx (which directory i am mounting spam isnide nginx container)

/ (what is slash) entire root directory of host system
here i have mounted entire root directory of a host sytem to a container

docker exec -it b49cb9418097 bash
root@b49cb9418097:/# ls -l
root@b49cb9418097:/# cd /
root@b49cb9418097:/# ls -l
lrwxrwxrwx    1 root root    7 Jul 22 00:00 bin -> usr/bin
drwxr-xr-x    2 root root    6 Mar 29 17:20 boot
drwxr-xr-x    5 root root  340 Aug  2 17:40 dev
drwxr-xr-x    1 root root   41 Jul 23 07:14 docker-entrypoint.d
-rwxr-xr-x    1 root root 1620 Jul 23 07:14 docker-entrypoint.sh
drwxr-xr-x    1 root root   19 Aug  2 17:40 etc
drwxr-xr-x    2 root root    6 Mar 29 17:20 home
lrwxrwxrwx    1 root root    7 Jul 22 00:00 lib -> usr/lib
lrwxrwxrwx    1 root root    9 Jul 22 00:00 lib64 -> usr/lib64
drwxr-xr-x    2 root root    6 Jul 22 00:00 media
drwxr-xr-x    2 root root    6 Jul 22 00:00 mnt
drwxr-xr-x    2 root root    6 Jul 22 00:00 opt
dr-xr-xr-x  222 root root    0 Aug  2 17:40 proc
drwx------    2 root root   37 Jul 22 00:00 root
drwxr-xr-x    1 root root   23 Aug  2 17:40 run
lrwxrwxrwx    1 root root    8 Jul 22 00:00 sbin -> usr/sbin
dr-xr-xr-x.  19 root root  267 Aug  2 15:45 spam
drwxr-xr-x    2 root root    6 Jul 22 00:00 srv
dr-xr-xr-x   13 root root    0 Aug  2 17:40 sys
drwxrwxrwt    2 root root    6 Jul 22 00:00 tmp
drwxr-xr-x    1 root root   66 Jul 22 00:00 usr
drwxr-xr-x    1 root root   19 Jul 22 00:00 var
root@b49cb9418097:/# cd spam
root@b49cb9418097:/spam# ls -l
total 16
dr-xr-xr-x.   2 root root    6 Aug  9  2021 afs
lrwxrwxrwx.   1 root root    7 Aug  9  2021 bin -> usr/bin
dr-xr-xr-x.   5 root root 4096 Feb 22 19:40 boot
drwxr-xr-x   17 root root 3220 Aug  2 15:45 dev
drwxr-xr-x.  91 root root 8192 Aug  2 16:31 etc
drwxr-xr-x.   4 root root   39 Jun 24 13:12 home
lrwxrwxrwx.   1 root root    7 Aug  9  2021 lib -> usr/lib
lrwxrwxrwx.   1 root root    9 Aug  9  2021 lib64 -> usr/lib64
drwxr-xr-x.   2 root root    6 Aug  9  2021 media
drwxr-xr-x.   2 root root    6 Aug  9  2021 mnt
drwxr-xr-x.   4 root root   35 Aug  2 15:49 opt
dr-xr-xr-x  221 root root    0 Aug  2 15:44 proc
dr-xr-x---.   4 root root  172 Aug  2 17:33 root
drwxr-xr-x   33 root root  980 Aug  2 17:04 run
lrwxrwxrwx.   1 root root    8 Aug  9  2021 sbin -> usr/sbin
drwxr-xr-x.   2 root root    6 Aug  9  2021 srv
drwxr-xr-x.   2 root root    6 Feb 22 19:37 swap
dr-xr-xr-x   13 root root    0 Aug  2 15:44 sys
drwxrwxrwt    9 root root  180 Aug  2 17:43 tmp
drwxr-xr-x.  12 root root  144 Feb 22 19:37 usr
drwxr-xr-x.  19 root root  264 Jun 24 13:08 var
root@b49cb9418097:/spam# cd /home/ec2-user/
root@b49cb9418097:/spam/home/ec2-user# ls -l
total 0
drwxr-xr-x 6 1001 1001 131 Aug  2 17:34 expense-docker
drwxr-xr-x 2 1001 1001  91 Aug  2 17:29 most-secure
drwxr-xr-x 4 1001 1001  62 Aug  2 17:26 shipping

see you got underlying host storage access. how is this possible? this is possible container is running with root user.
so, you should not run containers as root as container or priviled containers. docker best practice not run container as privileged user.

here mysql container is also running as root user. if used as malicious we can know other projects database details also like customers numbers and other confidential information.
so, you should run container as normal user

/var/lib/mysql is where mysql stores files while adding a user in dockerfile of mysql to remove root user privileges we need to give that user access mysql files access too. so change ownership that directories to normal user. see mysql dockerfile in expense docker.

docker exec -it backend bash (will not work for alpine image)
docker exec -it backend sh (will work for alpine image)

Layering
-----------
layer1 --> FROM nginx
layer2 --> FROM nginx + RUN rm -rf /usr/share/nginx/html/index.html --> create image

create layer2 container from layer2 image

layer3 image = layer2 + RUN rm -rf /etc/nginx/nginx.conf

create layer3 container from layer3 image

layer4 image = layer3 + RUN rm -rf /etc/nginx/conf.d/default.conf

FROM nginx
RUN rm -rf /usr/share/nginx/html/index.html
RUN rm -rf /etc/nginx/nginx.conf
RUN rm -rf /etc/nginx/conf.d/default.conf
USER nginx
(if we write same instructions as above write an extra line at end. it will not create again new 4 layers. it will pull layer 4 from previous upon it will 
 build layer 5. Otherwise, if it will build all layers for everything no matter how big storage you will create that storage will not be enough)

FROM nginx
RUN rm -rf /usr/share/nginx/html/index.html

in git hub it will store only difference. it will not store from the scratch again.

frontend     v1.0      067a11d14309   4 hours ago   189MB
if i push this to docker hub it will go there as layers

FROM nginx
RUN rm -rf /usr/share/nginx/html/index.html
RUN rm -rf /etc/nginx/nginx.conf
RUN rm -rf /etc/nginx/conf.d/default.conf
(for example if push this to docker hub it will go there as layers. here as 4 layers)

FROM nginx
RUN rm -rf /usr/share/nginx/html/index.html
RUN rm -rf /etc/nginx/nginx.conf
RUN rm -rf /etc/nginx/conf.d/default.conf
USER nginx
(for example if someone else is pushing this to docker we see that only 5th line is different remaing all same as previous. it will check with these 4  
 instructions do i have already an image in docker storage. we know that there is already layer 4 image in dockerhub. so, docker will pull layer 4 image and  
 run layer 5 instruction on top of it. So, by doing this way docker is able to manager Memory. Otherwise, if it will build all layers for everything no  
 matter how big storage you will create that storage will not be enough)

Even in your local storage also this might same or different i don't he said only about hub.

What is Docker Layers?
------------------------
Docker Stores the images as layers. First Instruction will be Layer 1 on top of Layer 1 it will run Layer 2 and it will Store Layer 2 and on top of Layer 2 it will run Layer 3. it will store layer 3 as separate.

docker system prune -a (prune means delete)
WARNING! This will remove:
  - all stopped containers
  - all networks not used by at least one container
  - all images without at least one container associated to them
  - all build cache

docker builder prune
WARNING! This will remove all dangling build cache. 

docker image prune
WARNING! This will remove all dangling images.

set DOCKER_BUILDKIT=0
cd backend
docker build -t backend:v1.0 .

env | grep DOCKER_BUILDKIT
set DOCKER_BUILDKIT=0
env | grep DOCKER_BUILDKIT
export DOCKER_BUILDKIT=0
env | grep DOCKER_BUILDKIT

deleting cache again

docker system prune -a
docker builder prune
docker image prune

docker build -t backend:v1.0 .
(now you can see layering process while image building)

docker follows intermediate containers and layering approach for best storage. docker first it will create the container out of first instruction runs the second instruction. create image out of it and then delete the intermediate container.

docker login
(after this give your credentials)

docker tag backend:v1.0 ishahulahmed/backend:v1.0
docker push ishahulahmed/backend:v1.0
(while pushing you can see it will not push as entire image. it will push as layers)
The push refers to repository [docker.io/ishahulahmed/backend]
855bdb9562ef: Preparing
855bdb9562ef: Pushed
9a5010e7e3be: Pushed
757849a4c551: Pushed
042558fd2c9b: Pushed
f596146bb853: Pushed
364f90d01431: Mounted from library/node
d21971417e92: Mounted from library/node
aba337309a79: Mounted from library/node
78561cef0761: Mounted from library/node
v1.0: digest: sha256:7a67a1364449abc572ab788bcfba904281f4573e609e6c0f3ab5231f7bf3abbc size: 2406

docker tag frontend:v1.0 ishahulahmed/frontend:v1.0
docker push ishahulahmed/frontend:v1.0
The push refers to repository [docker.io/ishahulahmed/frontend]
9f995ae959bf: Preparing
fb54b18571ce: Preparing
3804c6ff166f: Preparing
ed81ad2c57b0: Preparing
5db08f251485: Preparing
53efab4d979c: Pushed
fdebcb7326e5: Pushed
60e72fbb314e: Mounted from library/nginx
599e8de62018: Mounted from library/nginx
09581b9299a2: Mounted from library/nginx
a39383416a22: Mounted from library/nginx
a6355e7844d5: Mounted from library/nginx
fcfa12460e7d: Mounted from library/nginx
e0781bc8667f: Mounted from library/nginx
v1.0: digest: sha256:2ac00d6a46119505103e60510621ba526c05b6db182952e783f2d66501f637b2 size: 3232

docker tag mysql:v1.0 ishahulahmed/mysql:v1.0
docker push ishahulahmed/mysql:v1.0
The push refers to repository [docker.io/ishahulahmed/mysql]
4ba1ade8ee82: Preparing
007821eeee25: Preparing
77ee579f02fd: Preparing
fe99df7dedb4: Preparing
c240e57ab2fa: Preparing
4ba1ade8ee82: Pushed
012aa1f0f19c: Mounted from library/mysql
d4a3c7a78c78: Mounted from library/mysql
69a7b1be7072: Mounted from library/mysql
6fcbf3180db6: Mounted from library/mysql
300303f807f3: Mounted from library/mysql
29c18dc695ca: Mounted from library/mysql
e08c762baae9: Mounted from library/mysql
2606c15a4838: Mounted from library/mysql
v1.0: digest: sha256:7c9fd164068e7bd2eb0855adfdc4010cb86b1265830125c57c37ad2fc6fac090 size: 3239

docker rm -f `docker ps -a -q`
docker rmi -f `docker images -a -q`






ChatGPT
---------
Dockerfile
------------
# Use an official Python runtime as a base image
FROM python:3.9-slim

# Set environment variables
ENV APP_ENV=production

# Install dependencies
RUN pip install --no-cache-dir flask

# Create a directory for the application
RUN mkdir /app

# Copy the application code into the image
COPY app.py /app/

# Set the working directory
WORKDIR /app

# Expose port 5000
EXPOSE 5000

# Define the command to run the application
CMD ["python", "app.py"]


Layering Breakdown with Intermediate Containers
--------------------------------------------------
1) Base Image Layer (Layer 1): FROM python:3.9-slim
   a) Description: Starts with the base image, python:3.9-slim, which includes its own layers (e.g., base OS, Python runtime).
   b) Intermediate Container: Not applicable. This layer is directly inherited from the base image.

2) Environment Variable Layer (Layer 2): ENV APP_ENV=production
   a) Description: Sets an environment variable APP_ENV in the image.
   b) Intermediate Container: Not applicable. This change is applied directly as a new layer.

3) Install Dependencies Layer (Layer 3): RUN pip install --no-cache-dir flask
   a) Intermediate Container: Docker creates a new intermediate container from the image state of Layer 2. The command pip install --no-cache-dir flask is   
                              executed inside this container.
   b) Layer: Layer 3 includes the installed Flask package. The intermediate container is discarded after the layer is committed.

4) Create Directory Layer (Layer 4): RUN mkdir /app
   a) Intermediate Container: Docker creates a new intermediate container from the image state of Layer 3. The command mkdir /app is executed inside this 
                              container.
   b) Layer: Layer 4 includes the creation of the /app directory. The intermediate container is discarded after the layer is committed.

5) Copy Application Code Layer (Layer 5): COPY app.py /app/
   a) Description: Copies the app.py file from the host machine into the /app/ directory in the image.
   b) Intermediate Container: Not applicable. Docker directly applies the file copy changes to create Layer 5.

6) Set Working Directory Layer (Layer 6): WORKDIR /app
   a) Description: Sets the working directory for any subsequent instructions to /app.
   b) Intermediate Container: Not applicable. This change is applied directly as Layer 6.

7) Expose Port Layer (Layer 7): EXPOSE 5000
   a) Description: Documents that the container listens on port 5000.
   b) Intermediate Container: Not applicable. This change is applied directly as Layer 7.

8) Command to Run the Application Layer (Layer 8): CMD ["python", "app.py"]
   a) Description: Specifies the default command to run when the container starts.
   b) Intermediate Container: Not applicable. This change is applied directly as Layer 8.

Summary of Intermediate Containers
------------------------------------
1) Intermediate Containers Created:

   a) For RUN Instructions:
     
      i) RUN pip install --no-cache-dir flask
     ii) RUN mkdir /app
    iii) Docker creates an intermediate container for each RUN instruction. The command is executed inside the container, and the resulting changes are 
         committed as a new layer.

2) No Intermediate Containers Created:

   a) For FROM Instruction: Base image setup.
   b) For ENV Instruction: Environment variable settings.
   c) For COPY Instruction: File copying from the host.
   d) For WORKDIR Instruction: Working directory configuration.
   e) For EXPOSE Instruction: Port exposure documentation.
   f) For CMD Instruction: Default command configuration.

This breakdown should give a clear picture of how Docker handles intermediate containers and layering during the image build process.


if there are no images locally. then it will pull from docker hub you need to give credentials if they are you images which are private.

Docker follows layering approach for the effective storage. each instruction is running in separate layer intermediate container is created out of it and this process goes on all the intermediate containers will be remove docker will keep the layers. image is nothing but layers.

RUN addgroup -S expense && adduser -S expense -G expense 
RUN mkdir /opt/server \
RUN chown expense:expense -R /opt/server

if you write like this docker will create a new layer for every instruction and build process will become slow.

RUN addgroup -S expense && adduser -S expense -G expense \
    && mkdir /opt/server \
    && chown expense:expense -R /opt/server

we are speeding up build process by decreasing number of layers.

Optimize Layer Caching
-------------------------
Layer Order: Order your Dockerfile instructions to maximize layer caching. Frequently changing commands should be at the end of the Dockerfile.
Combine Commands: Combine Command where possible to reduce the number of layers, but balance it with readability.

if chain link is broken in the middle all other depending on it will not work. if link at the end is broken it will be less tedius.
it will create layers again from where it is broken. if it is broken at the end only the last few layers it will create. previous created will come directly from cache.

docker push ishahulahmed/backend:v1.0
67473ab1be4b: Pushed
0bf887fc4b28: Pushed
bdaa9fc83a2e: Pushed
6b1db3dedbaa: Pushed
61a4672d547d: Layer already exists
64afd0417f62: Layer already exists
ccd1c30cd963: Layer already exists
9435f06ff8e3: Layer already exists
v1.0: digest: sha256:e53bf66b29bcbf4f820a9150b620cc3c88c0e16a6d1610797fdfde4c8 size: 1992

in realtime, we will not keep our images in docker hub. we will place it in ECR (Elastic Container Registry)
create ECR repository as backend in keep it as private since backend is private
we will give role to ec2-instance or aws configure command
if you want to push for example backend image to ecr first 
login to ecr as how you login docker
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 3150696547000.dkr.ecr.us-east-1.amazonaws.com

after login to ecr tag you build
docker tag ishahulahmed/backend:v1.0 3150696547000.dkr.ecr.us-east-1.amazonaws.com/backend:v1.0
 
/backend:v1.0 this is ecr url this is where everything is stored. now i want to push it
docker push ishahulahmed/backend:v1.0 3150696547000.dkr.ecr.us-east-1.amazonaws.com/backend:v1.0

if there is vulenrability in image due to us. straighforward we can make changes in dockerfile. if there is vulenerability due to base image then we need to do patching.

docker system prune 
will help us to remove unused images and containers and cache. it will help us to save storage.



